{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9130a029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a846bb69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb368553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "import awswrangler as wr\n",
    "#import s3fs\n",
    "#from fastparquet import write\n",
    "\n",
    "import joblib\n",
    "\n",
    "#modeling\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import add_constant\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split,ShuffleSplit, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay,\\\n",
    "classification_report, accuracy_score, f1_score, precision_recall_curve\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "from scipy.stats import randint as sp_randInt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, log_loss, brier_score_loss\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "import lightgbm as lgbm\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8229628b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613379f",
   "metadata": {},
   "source": [
    "#### Laod Data from S-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f59fe84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "s3 = session.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55df1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'ppsg-collections'\n",
    "file_name = '2021-06-01/consolidated/random_data/consolidated_sample_expanded_treated.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb66c6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 51s, sys: 4min 59s, total: 6min 51s\n",
      "Wall time: 44.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "obj = s3.get_object(Bucket = bucket_name, Key = file_name)\n",
    "df = pd.read_parquet(io.BytesIO(obj['Body'].read())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75258d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df =  df[df['PastDue'] <=31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba45c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_date = '2021-02-01'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2093ae1c",
   "metadata": {},
   "source": [
    "#### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "943d6ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#roc curve\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc095786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_importance_features(model):\n",
    "    clf = model\n",
    "    feature_importances_data = []\n",
    "    features = train_X.columns\n",
    "    for feature_name, feature_importance in zip(features, clf.feature_importances_):\n",
    "        feature_importances_data.append({\n",
    "            'feature': feature_name,\n",
    "            'importance': feature_importance\n",
    "        })\n",
    "\n",
    "    # Plot the results\n",
    "    pd.DataFrame(feature_importances_data)\\\n",
    "        .set_index('feature')\\\n",
    "        .sort_values(by='importance')[-15::]\\\n",
    "        .plot(title='Top 15 most important features: '+ str(type(model).__name__),\n",
    "              kind='barh',figsize=(10, 6),\n",
    "              color='#348ABD',alpha=0.6,\n",
    "              lw='1', edgecolor='#348ABD',grid=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee1ecfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#key performance metrics\n",
    "def fn_metrics(act, prob, pred):\n",
    "    #ROC\n",
    "    fpr, tpr, thresholds = roc_curve(act, prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plot_roc_curve(fpr, tpr)\n",
    "    \n",
    "    print ('ROC value of:{:.2f}'.format(roc_auc*100))\n",
    "    print ('Accuracy:{:.2f}'.format(accuracy_score(act, pred)*100))\n",
    "    print ('F1 score:{:.2f}'.format(f1_score(act, pred)*100))\n",
    "    print ('Recall:{:.2f}'.format(recall_score(act, pred)*100))\n",
    "    print ('Precision:{:.2f}'.format(precision_score(act, pred)*100))\n",
    "    print ('\\n clasification report:\\n',classification_report(act, pred))\n",
    "     \n",
    "    #plot confusion matrix    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(8,6))\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    ConfusionMatrixDisplay(confusion_matrix(pred, act, labels=[1,0]), \n",
    "                       display_labels=['Yes_Down2','No_Down2']).plot(values_format=\".0f\",ax=ax)\n",
    "\n",
    "    ax.set_xlabel(\"Actual Label\")\n",
    "    ax.set_ylabel(\"Predicted Label\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c77ec4",
   "metadata": {},
   "source": [
    "#### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2985144",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "'Down2',\n",
    "'nextpaymentduedt',\n",
    "'CampaignProfile',\n",
    "'rollback',\n",
    "                        \n",
    "#origination\n",
    "'FICOScore',\n",
    "'FICO_flag',\n",
    "'FICO_200',\n",
    "'LTV',\n",
    "#'currentLTV', \n",
    "'FrontDTI', \n",
    "'origrate',\n",
    "'origbal', \n",
    "'origterm', \n",
    "'origpropvalue',\n",
    "                       \n",
    "#balance related\n",
    "'current_total_pmt',\n",
    "'currentpipayment',\n",
    "'priorupb',\n",
    "'upb',\n",
    "'upb_change',\n",
    "'TI_change',   \n",
    "'PI_change',\n",
    "'Escrow_change',            \n",
    "'curtailment_3months',  \n",
    "'curtailment_6months',\n",
    "'curtailment_12months',\n",
    "\n",
    "#income related            \n",
    "'TI',\n",
    "'EMPL_Income',\n",
    "'OTHR_Income',\n",
    "'PNSN_Income',\n",
    "'RNTL_Income',\n",
    "'SEMP_Income',\n",
    "'SSEC_Income',\n",
    "'EMPL_Income_per', \n",
    "'OTHR_Income_per', \n",
    "'PNSN_Income_per', \n",
    "'RNTL_Income_per',\n",
    "'SEMP_Income_per', \n",
    "'SSEC_Income_per',\n",
    "            \n",
    "#time related \n",
    "'age',\n",
    "'CurrentAmortTerm',\n",
    "'nextpaymentdue_day',\n",
    "'nextpayment_weekday',\n",
    "'days_in_month',            \n",
    "            \n",
    "#dynamic variabels\n",
    "'rundt_day',\n",
    "'loanstatusid_lag1',\n",
    "    \n",
    "    \n",
    "# flags \n",
    "'forebearance_status_flag',\n",
    "'drafting_ind_flag',\n",
    "'Covid_flag',\n",
    "'selfemployed_flag',\n",
    "'DUtype_flag',\n",
    "'doctype_flag',\n",
    "'tract_income_category_flag',\n",
    "'application_income_category_flag',\n",
    "'mod_flag',\n",
    "'draft_flag',\n",
    "'ACHPmtSet_flag',\n",
    "'EscrowFlag',\n",
    "'CRAFlag',\n",
    "'HomeReadyHomePossibleFlag',\n",
    "'streamline_flag',\n",
    "'HighBalanaceFlag',\n",
    "    \n",
    "#others \n",
    "'producttype',\n",
    "'priorstatus',\n",
    "'LoanPurpose',\n",
    "'borrowercount',\n",
    "'fsttimehomebuyer',  \n",
    "'PropState',\n",
    "#'zipcode',\n",
    "'CBSACode',\n",
    "'samemailingandpropertyzip',\n",
    "'PropertyType',\n",
    "'Units',\n",
    "'Occupancy',\n",
    "'channel',\n",
    "'Entity',\n",
    "'PaymentInFullStopCode',\n",
    "'apprbucket',\n",
    "'amorttype',\n",
    "'termbucket',\n",
    "\n",
    "           \n",
    "#Right Party Contact \n",
    "'rpc_3months',\n",
    "'rpc_6months',\n",
    "'rpc_12months',\n",
    "'rpc_24months',\n",
    "            \n",
    "#Broken Promise\n",
    "'bph_3months',\n",
    "'bph_6months',\n",
    "'bph_12months',\n",
    "'bph_24months',\n",
    "            \n",
    "#Reversal related             \n",
    "'reversalcount_3months',\n",
    "'reversalcount_6months',\n",
    "'reversalcount_12months',\n",
    "'reversalamt_3months',\n",
    "'reversalamt_6months',\n",
    "'reversalamt_12months',  \n",
    "      \n",
    "# NSF\n",
    "'nsfcount_3months',\n",
    "'nsfcount_6months',\n",
    "'nsfcount_12months',\n",
    "'nsfamt_3months',\n",
    "'nsfamt_6months',\n",
    "'nsfamt_12months',\n",
    "    \n",
    "# CA values,\n",
    "#'leadg_Value', \n",
    "'OpenLossDraftClaimAmount',\n",
    "    \n",
    "#Delinquency, BK related\n",
    "'status24months',\n",
    "#'bk24months',\n",
    "'monthssincecurrent',\n",
    "'monthssince30',\n",
    "'monthssince60',\n",
    "'monthssince90',\n",
    "'monthssince120',\n",
    "'monthssinceFC',\n",
    "'monthssinceBK',\n",
    "'prior24historyCurrent',\n",
    "'prior24history30D',\n",
    "'prior24history60D',\n",
    "'prior24history90D',\n",
    "'prior24history120D',\n",
    "'prior24historyFC',\n",
    "'prior12historyCurrent',\n",
    "'prior12history30D',\n",
    "'prior12history60D',\n",
    "'prior12history90D',\n",
    "'prior12history120D',\n",
    "'prior12historyFC',\n",
    "'prior6historyCurrent',\n",
    "'prior6history30D',\n",
    "'prior6history60D',\n",
    "'prior6history90D',\n",
    "'prior6history120D',\n",
    "'prior6historyFC',\n",
    "'Dlq_Count_12M',            \n",
    "\n",
    "            \n",
    "#avg payment day\n",
    "#'AvgPmtDay_3M',\n",
    "#'AvgPmtDay_6M', \n",
    "#'AvgPmtDay_12M'\n",
    "'AvgPmtDay_3M_bucket',\n",
    "'AvgPmtDay_6M_bucket',\n",
    "'AvgPmtDay_12M_bucket',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bb0326d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28469560, 128)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_dataset =df[features]\n",
    "ml_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b68a1385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28207780, 128)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_dataset=ml_dataset.dropna()\n",
    "ml_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58700baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e9b62e",
   "metadata": {},
   "source": [
    "#### Pre-Processing: Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1294d219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CampaignProfile\n",
      "AvgPmtDay_3M_bucket\n",
      "AvgPmtDay_6M_bucket\n",
      "AvgPmtDay_12M_bucket\n",
      "rollback\n",
      "rundt_day\n",
      "FICO_flag\n",
      "FICO_200\n",
      "status24months\n",
      "loanstatusid_lag1\n",
      "forebearance_status_flag\n",
      "drafting_ind_flag\n",
      "Covid_flag\n",
      "selfemployed_flag\n",
      "DUtype_flag\n",
      "doctype_flag\n",
      "CRAFlag\n",
      "tract_income_category_flag\n",
      "application_income_category_flag\n",
      "mod_flag\n",
      "draft_flag\n",
      "ACHPmtSet_flag\n",
      "EscrowFlag\n",
      "HomeReadyHomePossibleFlag\n",
      "streamline_flag\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cat_features = [\n",
    "'CampaignProfile',\n",
    "'AvgPmtDay_3M_bucket',\n",
    "'AvgPmtDay_6M_bucket',\n",
    "'AvgPmtDay_12M_bucket',\n",
    "'rollback',\n",
    "'rundt_day',    \n",
    "'FICO_flag',\n",
    "'FICO_200',    \n",
    "'status24months',\n",
    "'loanstatusid_lag1',    \n",
    "'forebearance_status_flag',\n",
    "'drafting_ind_flag',\n",
    "'Covid_flag',\n",
    "'selfemployed_flag',\n",
    "'DUtype_flag',\n",
    "'doctype_flag',\n",
    "'CRAFlag',\n",
    "'tract_income_category_flag',\n",
    "'application_income_category_flag',\n",
    "'mod_flag',\n",
    "'draft_flag',\n",
    "'ACHPmtSet_flag',\n",
    "'EscrowFlag',\n",
    "'HomeReadyHomePossibleFlag',\n",
    "'streamline_flag',\n",
    "'HighBalanaceFlag', \n",
    "'producttype',\n",
    "'priorstatus',\n",
    "'LoanPurpose',\n",
    "'borrowercount',\n",
    "'fsttimehomebuyer',  \n",
    "'PropState',\n",
    "#'zipcode',\n",
    "'CBSACode',\n",
    "'PropertyType',\n",
    "'Units',\n",
    "'Occupancy',\n",
    "'channel',\n",
    "'samemailingandpropertyzip',\n",
    "'Entity',\n",
    "'PaymentInFullStopCode',\n",
    "'apprbucket',\n",
    "'amorttype',\n",
    "'termbucket'\n",
    "]   \n",
    "\n",
    "for f in ml_dataset[cat_features]:\n",
    "    print(f)\n",
    "    lbl = preprocessing.LabelEncoder()\n",
    "    lbl.fit(list(ml_dataset[f].values))\n",
    "    ml_dataset[f] = lbl.transform(list(ml_dataset[f].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585e157a",
   "metadata": {},
   "source": [
    "#### Pre-processing: Numerical  (Min Max scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62980efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_features = [x for x in ml_dataset.columns if x not in [cat_features, 'Down2', 'nextpaymentduedt']]\n",
    "\n",
    "for f in ml_dataset[num_features] :\n",
    "    if ml_dataset[f].dtype in ('float', 'int'):\n",
    "        _min = ml_dataset[f].min()\n",
    "        _max = ml_dataset[f].max()\n",
    "        scale = _max - _min\n",
    "        shift = _min\n",
    "\n",
    "        ml_dataset[f] = (ml_dataset[f] - shift).astype(np.float64) / scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ebab4",
   "metadata": {},
   "source": [
    "#### Imbalance Data Treatment (simplified version - oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c3b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Resampling: upsample of Fraud count\n",
    "\n",
    "# # Separate majority and minority classes\n",
    "# ml_dataset_majority = ml_dataset[ml_dataset.Down2==0]\n",
    "# ml_dataset_minority = ml_dataset[ml_dataset.Down2==1]\n",
    "\n",
    "# # Upsample minority class\n",
    "# ml_dataset_minority_upsampled = resample(ml_dataset_minority,\n",
    "#                                  replace=True,     # sample with replacement\n",
    "#                                  n_samples=500000,  #arbitrary number   \n",
    "#                                  random_state=123) # reproducible results\n",
    "\n",
    "# # Combine majority class with upsampled minority class\n",
    "# ml_dataset= pd.concat([ml_dataset_majority, ml_dataset_minority_upsampled])\n",
    "\n",
    "# # Display new class counts\n",
    "# ml_dataset.Down2.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681f1a5d",
   "metadata": {},
   "source": [
    "#### Create a Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5240f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_dataset['__target__'] = ml_dataset['Down2']\n",
    "del ml_dataset['Down2']\n",
    "\n",
    "# Remove rows for which the target is unknown.\n",
    "ml_dataset = ml_dataset[~ml_dataset['__target__'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a81f458",
   "metadata": {},
   "source": [
    "#### Split Train/Validation/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a56b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data < outdate\n",
    "train = ml_dataset[ml_dataset['nextpaymentduedt'] < out_date]\n",
    "\n",
    "# split train to train and  test (validation) data\n",
    "train, valid = train_test_split(train, test_size=0.15, random_state=101)\n",
    "\n",
    "# test data >= outdate\n",
    "test = ml_dataset[ml_dataset['nextpaymentduedt'] >= out_date]\n",
    "\n",
    "train = train.drop(columns=['nextpaymentduedt'])\n",
    "valid = valid.drop(columns=['nextpaymentduedt'])\n",
    "test = test.drop(columns=['nextpaymentduedt'])\n",
    "\n",
    "#train, test = train_test_split(ml_dataset, test_size=0.2, random_state=101)\n",
    "print ('Train data has %i rows and %i columns' % (train.shape[0], train.shape[1]))\n",
    "print ('Valiation data has %i rows and %i columns' % (valid.shape[0], valid.shape[1]))\n",
    "print ('Test data has %i rows and %i columns' % (test.shape[0], test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2ce745",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train.drop('__target__', axis=1)\n",
    "valid_X = valid.drop('__target__', axis=1)\n",
    "test_X = test.drop('__target__', axis=1)\n",
    "\n",
    "train_Y = np.array(train['__target__'])\n",
    "valid_Y = np.array(valid['__target__'])\n",
    "test_Y = np.array(test['__target__'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcc8c2d",
   "metadata": {},
   "source": [
    "#### LGBM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d6576",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# with validation and early stoppage: ROC is better than recall\n",
    "\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "\n",
    "t = time.time()\n",
    "folds = 6    #10\n",
    "param_comb = 6  #2 #5 #10\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(objective = 'binary', boosting_type = 'gbdt',  random_state=101)\n",
    "#                              early_stopping_rounds =30, \n",
    "lgb_parameters  = {\n",
    "             ''learning_rate': sp_randFloat(),\n",
    "             'n_estimators':sp_randInt(200, 500), \n",
    "             'max_depth':sp_randInt(5, 50), \n",
    "             'num_leaves': sp_randInt(10, 100), \n",
    "             'min_child_samples': sp_randInt(100, 500), \n",
    "             'min_child_weight': [1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "             #'subsample': sp_randFloat(), \n",
    "             'subsample_for_bin': [50000, 100000, 200000, 300000, 400000, 500000],\n",
    "             'colsample_bytree': sp_randFloat(),\n",
    "             'reg_alpha': [0, 1e-1, 10,  20, 50, 100, 200],\n",
    "             'reg_lambda': [0, 1e-1, 10, 20, 50, 100, 200],\n",
    "             'scale_pos_weight': [5, 7, 8, 10, 15, 20, 25],\n",
    "             'min_split_gain': [0.5e-1, 1e-1, 2e-1, 3e-1, 5e-1, 7.5e-1, 1],\n",
    "             'bagging_fraction': sp_randFloat()\n",
    "\n",
    "#socring parameters \n",
    "scoring = { 'AUC': 'roc_auc',  'Log_loss': 'neg_log_loss', 'F1': 'f1','Recall': 'recall', 'Precision': 'precision'} \n",
    "\n",
    "# stratified k-fold\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 101)\n",
    "\n",
    "\n",
    "# Randomized Grid Search\n",
    "random_search = RandomizedSearchCV(lgb_clf, param_distributions=lgb_parameters, n_iter=param_comb, \n",
    "                                     scoring= scoring,  refit='Recall',   #Recall #AUC #Log_Loss #Brier_loss\n",
    "                                     #n_jobs=-1,\n",
    "                                     cv=skf.split(train_X, train_Y), verbose=3, random_state=101)\n",
    "\n",
    "\n",
    "# fit training data and eval data for early stopping (validate with validation data)\n",
    "random_search.fit(train_X, train_Y, eval_set = [(valid_X, valid_Y)], eval_metric =  'recall',\n",
    "                                                early_stopping_rounds = 50, verbose=50)\n",
    "#eval_metric = 'auc', 'recall', ['recall','binary_logloss']\n",
    "\n",
    "# results\n",
    "tune_results = random_search.cv_results_\n",
    "\n",
    "#best parameter setting\n",
    "print('Best Parameter setting: ',  random_search.best_params_)\n",
    "    \n",
    "#best ROC score\n",
    "print('Best score Training: ', random_search.best_score_)\n",
    "\n",
    "print(f'Done, time = {time.time() - t}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f156abf",
   "metadata": {},
   "source": [
    "#### Export model, create a pickle object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b2bcaf",
   "metadata": {},
   "source": [
    "#### Method 1. Export to Local Python and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d47908",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to local\n",
    "joblib.dump(random_search.best_estimator_, 'lgbm_0610_model_replicated.pkl')\n",
    "\n",
    "#load pickle local python\n",
    "clf_tuned_lgb =joblib.load('lgbm_0610_model_replicated.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714e5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_tuned_lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4a801",
   "metadata": {},
   "source": [
    "#### Method 2. Export to S3 and Load from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525c177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to S3\n",
    "import pickle\n",
    "pickle_file = 'lgbm_0610_model_replicated.pkl'\n",
    "file_path= 'Feb21_test/Model/'\n",
    "key_name = file_path + pickle_file\n",
    "\n",
    "pickle_byte_obj = pickle.dumps(random_search.best_estimator_) \n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(bucket_name,key_name).put(Body=pickle_byte_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cf6df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model object from s3\n",
    "bucket = boto3.resource(\"s3\").Bucket(bucket_name)\n",
    "with BytesIO() as modelfo:\n",
    "    bucket.download_fileobj(Key=key_name, Fileobj=modelfo)\n",
    "    clf_tuned_lgb = joblib.load(modelfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa01c9",
   "metadata": {},
   "source": [
    "#### Model Fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f545fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_importance_features(clf_tuned_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e9d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### In-sample metrics\n",
    "pred_Y_in = clf_tuned_lgb.predict(train_X)\n",
    "pred_Y_prob_in = clf_tuned_lgb.predict_proba(train_X)[:,1]\n",
    "tuned_lgb_prob_in = [train_Y, pred_Y_prob_in]\n",
    "fn_metrics(train_Y, pred_Y_prob_in, pred_Y_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ccb490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Out-of-sample metrics \n",
    "pred_Y_out = clf_tuned_lgb.predict(test_X)\n",
    "pred_Y_prob_out = clf_tuned_lgb.predict_proba(test_X)[:,1]\n",
    "tuned_lgb_prob_out = [test_Y, pred_Y_prob_out]\n",
    "\n",
    "#print out ROC curve, metrics, and confuction matrix\n",
    "fn_metrics(test_Y, pred_Y_prob_out, pred_Y_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cae36b",
   "metadata": {},
   "source": [
    "#### In-Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34cd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "## in-sample results \n",
    "#df_in_predict = pd.DataFrame({'prob': pred_Y_prob_in, 'predict': pred_Y_in}, columns=['prob', 'predict'], index = train_X.index.copy())\n",
    "\n",
    "# Build scored dataset\n",
    "#results_in = df.join(df_in_predict, how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d0fbd0",
   "metadata": {},
   "source": [
    "#### Out-of-time Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8accdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ml_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908bbdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## out-of-sample results \n",
    "df_out_predict = pd.DataFrame({'prob': pred_Y_prob_out, 'predict': pred_Y_out}, columns=['prob', 'predict'], index = test_X.index.copy())\n",
    "\n",
    "# Build scored dataset\n",
    "results_out = df.join(df_out_predict, how='left')\n",
    "#results_out = results_out.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_in = results_out[results_out['nextpaymentduedt'] < outdate]\n",
    "df_out = results_out[results_out['nextpaymentduedt'] >= out_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de9b8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del train, train_X, valid, valid_X, test, test_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe26a09",
   "metadata": {},
   "source": [
    "#### Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c74bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#import awswrangler as wr\n",
    "try:\n",
    "    wr.s3.to_parquet(\n",
    "        df=df_out,\n",
    "        path='s3://ppsg-collections/2021-06-01/processing/feb21_out_0610.parquet'\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b74830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ##import awswrangler as wr\n",
    "# wr.s3.to_parquet(\n",
    "#     df=results_out,\n",
    "#     path='s3://ppsg-collections/2021-06-01/processing/results_out_0610.parquet'\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
